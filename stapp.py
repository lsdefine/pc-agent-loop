import os, sys
if sys.stdout is None: sys.stdout = open(os.devnull, "w")
if sys.stderr is None: sys.stderr = open(os.devnull, "w")
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import time, json, re, threading
from agentmain import GeneraticAgent

st.set_page_config(page_title="Cowork", layout="wide")

@st.cache_resource
def init():
    agent = GeneraticAgent()
    if agent.llmclient is None:
        st.error("âš ï¸ æœªé…ç½®ä»»ä½•å¯ç”¨çš„ LLM æ¥å£ï¼Œè¯·åœ¨ mykey.py ä¸­æ·»åŠ  sider_cookie æˆ– oai_apikey+oai_apibase ç­‰ä¿¡æ¯åé‡å¯ã€‚")
        st.stop()
    else:
        threading.Thread(target=agent.run, daemon=True).start()
    return agent

agent = init()

st.title("ğŸ–¥ï¸ Cowork")

@st.fragment
def render_llm_switcher():
    current_idx = agent.llm_no
    st.caption(f"LLM Core: {current_idx}: {agent.llmclient.backends[current_idx].default_model}", help="ç‚¹å‡»åˆ‡æ¢å¤‡ç”¨é“¾è·¯")
    if st.button("åˆ‡æ¢å¤‡ç”¨é“¾è·¯"):
        agent.next_llm()
        st.rerun(scope="fragment")
    if st.button("å¼ºè¡Œåœæ­¢ä»»åŠ¡"):
        agent.abort()
        st.toast("å·²å‘é€åœæ­¢ä¿¡å·")
    if st.button("é‡æ–°æ³¨å…¥System Prompt"):
        agent.llmclient.last_tools = ''
        st.toast("ä¸‹æ¬¡å°†é‡æ–°æ³¨å…¥System Prompt")
with st.sidebar: render_llm_switcher()


def agent_backend_stream(prompt):
    display_queue = agent.put_task(prompt, source="user")
    try:
        while True:
            item = display_queue.get()
            if 'next' in item: yield item['next'] 
            if 'done' in item: 
                yield item['done']; break
    finally:
        agent.abort()

if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        response = ''
        for response in agent_backend_stream(prompt):
            message_placeholder.markdown(response + "â–Œ")
        message_placeholder.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
    st.session_state.last_reply_time = int(time.time())

st.markdown(f"""<div id="last-reply-time" style="display:none">{st.session_state.get('last_reply_time', int(time.time()))}</div>""", unsafe_allow_html=True)

