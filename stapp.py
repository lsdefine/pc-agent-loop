import os, sys
if sys.stdout is None: sys.stdout = open(os.devnull, "w")
if sys.stderr is None: sys.stderr = open(os.devnull, "w")
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import time, json, re, threading
from agentmain import GeneraticAgent

st.set_page_config(page_title="Cowork", layout="wide")

@st.cache_resource
def init():
    agent = GeneraticAgent()
    if agent.llmclient is None:
        st.error("âš ï¸ æœªé…ç½®ä»»ä½•å¯ç”¨çš„ LLM æ¥å£ï¼Œè¯·åœ¨ mykey.py ä¸­æ·»åŠ  sider_cookie æˆ– oai_apikey+oai_apibase ç­‰ä¿¡æ¯åé‡å¯ã€‚")
        st.stop()
    else:
        threading.Thread(target=agent.run, daemon=True).start()
    return agent

agent = init()

st.title("ğŸ–¥ï¸ Cowork")

if "idle_buf" not in st.session_state: st.session_state.idle_buf = ""
if "messages" not in st.session_state: st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

@st.fragment
def render_llm_switcher():
    current_idx = agent.llm_no
    st.caption(f"LLM Core: {current_idx}")
    if st.button("åˆ‡æ¢å¤‡ç”¨é“¾è·¯"):
        agent.llm_no = (current_idx + 1) % len(agent.llmclient.raw_apis)
        st.rerun(scope="fragment")
    if st.button("å¼ºè¡Œåœæ­¢ä»»åŠ¡"):
        agent.abort()
        st.toast("å·²å‘é€åœæ­¢ä¿¡å·")
with st.sidebar: render_llm_switcher()

@st.fragment(run_every="1s")
def global_queue_listener():
    if agent.current_source != 'auto': return
    while not agent.display_queue.empty():
        item = agent.display_queue.get()
        if 'next' in item:
            st.session_state.idle_buf = item['next']
        if 'done' in item:
            st.session_state.messages.append({"role": "assistant", "content": f"{item['done']}"})
            st.session_state.idle_buf = ""
            st.rerun()
    if st.session_state.get("idle_buf"):
        with st.chat_message("assistant"):
            st.write(st.session_state.idle_buf + "â–Œ")

global_queue_listener()

def agent_backend_stream(prompt):
    agent.put_task(prompt, source="user")
    try:
        while True:
            item = agent.display_queue.get()
            if 'next' in item: yield item['next'] 
            if 'done' in item: break
    finally:
        agent.abort()
        print('User aborted the operation.')

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        response = ''
        for response in agent_backend_stream(prompt):
            message_placeholder.markdown(response + "â–Œ")
        message_placeholder.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})